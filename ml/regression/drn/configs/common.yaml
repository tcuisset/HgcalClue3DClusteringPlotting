# lightning.pytorch==2.0.2
seed_everything: true
model:
  drn:
    class_path: ml.dynamic_reduction_network.DynamicReductionNetwork
    init_args:
      input_dim: 4
      hidden_dim: 20
      k: 10
      output_dim: 1
      norm: 
       - 1
       - 1
       - 1
       - 1 #torch.tensor([ 1., 1., 1., 1.])
      dropout: 0.3
  loss:
    class_path: ml.regression.drn.modules.RatioCorrectedLoss
    init_args:
      coefs: [-0.2597882 , -0.24326517,  1.01537901]

  optimizer:
    class_path: AdamW
    init_args:
      lr: 1e-3
      weight_decay: 1e-3

  lr_scheduler:
    class_path: CyclicLRWithRestartsAdapter
    init_args:
      restart_period: 80
      t_mult: 1.2
      policy: cosine

data:
  reader: 
    class_path: ClueNtupleReader
    init_args:
      version: v41
      clueParams: cmssw
      datatype: sim_proton_v46_patchMIP
#  datasetComputationClass: ml.regression.drn.dataset_making.LayerClustersTensorMaker
  transformFct: null
  multiprocess_loader: false
  keepOnGpu: cuda:3

sigma_over_e_callback:
  fit_data: full
  every_n_epochs: 2

trainer:
  accelerator: gpu
  devices: [3]
  max_epochs: 50
  log_every_n_steps: null
  enable_checkpointing: true
  logger:
    class_path: TensorBoardLogger
    init_args:
      save_dir: .

  strategy: auto
  num_nodes: 1
  precision: 32-true
  fast_dev_run: false
  min_epochs: null
  max_steps: -1
  min_steps: null
  max_time: null
  limit_train_batches: null
  limit_val_batches: null
  limit_test_batches: null
  limit_predict_batches: null
  overfit_batches: 0.0
  val_check_interval: null
  check_val_every_n_epoch: 1
  num_sanity_val_steps: null
  enable_progress_bar: null
  enable_model_summary: null
  accumulate_grad_batches: 1
  gradient_clip_val: null
  gradient_clip_algorithm: null
  deterministic: null
  benchmark: null
  inference_mode: true
  use_distributed_sampler: true
  profiler: null
  detect_anomaly: false
  barebones: false
  plugins: null
  sync_batchnorm: false
  reload_dataloaders_every_n_epochs: 0
  default_root_dir: null

